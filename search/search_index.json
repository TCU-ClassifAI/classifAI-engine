{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"ClassifAI Engine Documentation <p>     ClassifAI engine is a RESTful API that provides the heavy lifting for classifAI through audio transcription, question categorization, and insights. Visit The Portal \u00bb Report Bug     \u00b7     Request Feature     \u00b7     About the Project </p> Looking for main classifAI documentation?"},{"location":"#getting-started","title":"Getting Started","text":"<p>Please read the installation guide for instructions on how to install the engine.</p> <p>For usage instructions, check out the API Documentation.</p>"},{"location":"#list-of-pages-of-documentation","title":"List of Pages of Documentation","text":"<ul> <li>Home</li> <li>About &gt; <ul> <li>About</li> <li>Change Log</li> </ul> </li> <li>API Reference<ul> <li>Transcription</li> <li>Classification</li> <li>Summarization</li> <li>API Key Management</li> </ul> </li> <li>Installation</li> <li>Contribution &gt; <ul> <li>Contribution Overview</li> <li>Add Documentation</li> <li>Style Guide</li> <li>Pre-Commit Hooks</li> </ul> </li> <li>Project Structure</li> <li>Transcription Model Information</li> <li>Question Categorization Model Information (TBD)</li> </ul>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#configuration-files","title":"Configuration files","text":"<p>There are a few server configuration files that you can use to customize the server. These files are located in the <code>config</code> directory of the server.</p>"},{"location":"configuration/#configpy","title":"config.py","text":"<p>This has things like the Flask app configuration.</p> <p>Here is an example of the <code>config.py</code> file:</p> <pre><code>TRANSCRIPTION_MODEL = \"large-v3\"\nCATEGORIZATION_MODEL = \"gemma\" # You can also use \"gpt\" but that involves setting up your API key\nSUMMARIZATION_MODEL = \"huggingface\" # You can also use \"gpt\"\nENV_TYPE = \"dev\"\nUPLOAD_FOLDER = \"raw_audio/\"\n</code></pre> <p>More information about how to set up your API key for the GPT models can be found in the OpenAI documentation Note that using GPT requires MONEYS.</p> <p>Note that <code>UPLOAD_FOLDER</code> is the directory where the raw audio files are stored. This is relative to <code>root</code> so the default is <code>classifAI-engine/raw_audio/</code>.</p>"},{"location":"configuration/#server-configuration","title":"Server configuration","text":"<p>This runs on a few different services, so there are diffierent ways to view logs. </p> <p>To view the logs for ClassifAI-engine, the flask server, you can run the following command:</p> <pre><code>sudo journalctl -u classifai\n</code></pre> <p>The Flask server service file is located at <code>/etc/systemd/system/classifai.service</code>. You can see it through <code>sudo systemctl cat classifai</code>.</p> <p>To view the logs for the Redis queue worker, you can run the following command:</p> <pre><code>sudo supervisorctl tail -5000 procname stderr\nsudo supervisorctl tail -f procname stdout\n</code></pre> <p>This is also run through the supervisor service file located at <code>/etc/supervisor/supervisord.conf</code>. Commands are imported through the <code>src</code> directory.</p>"},{"location":"configuration/#environment-variables","title":"Environment variables","text":"<p>There's a <code>.env</code> file in the root directory of the server that you can use to set environment variables. </p> <p>This has ENV, REDIS_PORT, and GEMMA_API_URL.</p> <p>Here is an example of the <code>.env</code> file:</p> <p><pre><code>ENV=development # This overrides whatever is in src/config/config.py. You can delete this line if you want to use the config.py file\nREDIS_PORT=6379 # This is the default port for Redis\nGEMMA_API_URL=http://localhost:5001 # Notice that the ClassifAI-engine Flask app is running on port 5000 by default, so the GEMMA API is running on port 5001\nLLAMA_API_URL=http://localhost:5003 # This is the URL for the LLAMA API\nHF_TOKEN=YOUR_HUGGINGFACE_API_KEY # This is the API key for the HuggingFace API\nOPENAI_API_KEY=YOUR_OPENAI_API_KEY # This is the API key for the OpenAI API (Optional)\n</code></pre> Recall that a the ENV variable is set in the <code>config.py</code> file, so if you set it in the <code>.env</code> file, it will override the <code>config.py</code> file. </p> <p>Furthermore, if you are using the GPT models, you will need to set the <code>OPENAI_API_KEY</code> variable in the <code>.env</code> file. Otherwise, it will not work.</p>"},{"location":"configuration/#cronjobs","title":"Cronjobs","text":"<p>There's one cronjob that runs every day to remove old audio files. This is simple enough that it's just in the <code>crontab</code> file.</p> <p>We permanently store audio_files in the web server, so there's no need to keep them in the raw_audio directory for more than a few days. To edit the cronjobs, you can run the following command:</p> <pre><code>sudo crontab -e\n# Below is the cronjob, if you're interested:\n5 3 * * * find /home/classgpu/classifAI-engine/src/raw_audio/ -mtime +3 -type f -delete\n# This will delete all files in the raw_audio directory that are older than 3 days, every day at 3:05 AM\n</code></pre>"},{"location":"configuration/#supervisor","title":"Supervisor","text":"<p>The server uses Supervisor to manage the Redis queue worker. The configuration file is located at <code>/etc/supervisor/supervisord.conf</code>.</p> <p>More information about Supervisor can be found in the Supervisor documentation.</p>"},{"location":"developer/","title":"Developer quickstart","text":"<p>Please read the full developer doccumentation at the site. </p>"},{"location":"developer/#useful-commands","title":"Useful commands","text":""},{"location":"developer/#check-services","title":"Check services!!!","text":"<pre><code>sudo systemctl status classifai\nsudo systemctl status gemma\nsudo supervisorctl status all\n</code></pre>"},{"location":"developer/#restart-services","title":"Restart services","text":"<pre><code>sudo systemctl restart classifai\nsudo systemctl restart gemma\nsudo supervisorctl restart all\n</code></pre>"},{"location":"developer/#read-logs","title":"Read logs","text":"<pre><code>sudo journalctl -u classifai\nsudo journalctl -u gemma\nsudo supervisorctl tail -5000 &lt;procname&gt; stderr\nsudo supervisorctl tail -f &lt;procname&gt; stdout # to follow the logs in real time\n</code></pre>"},{"location":"developer/#view-configuration-files-for-services","title":"View configuration files for services","text":"<pre><code>sudo systemctl cat classifai\nsudo systemctl cat gemma\nless /etc/supervisor/supervisord.conf\n</code></pre>"},{"location":"developer/#start-up-a-worker-without-supervisor","title":"Start up a worker without supervisor:","text":"<pre><code># from classifAI-engine/\nsource PATH_TO_VENV/bin/activate # try venv-3.10\nrq worker -c config.worker_config\n</code></pre>"},{"location":"developer/#general-running-commands","title":"General running commands","text":"<p><pre><code>fuser -k 5000/tcp\n</code></pre> - This command will kill the process running on port 5000. So, you can restart the server, assuming you are running the server on port 5000.</p> <p><pre><code>source PATH_TO_VENV/bin/activate\n</code></pre> - This command will activate the virtual environment. Reminder, you can generate the virtual environment by running the following command:</p> <pre><code>python3 -m venv PATH_TO_VENV\ndeactivate\npip install -r requirements.txt\n</code></pre>"},{"location":"developer/#checking-the-process","title":"Checking the process","text":"<p><pre><code>sudo systemctl status classifai\nsudo systemctl restart classifai\nsudo journalctl -u classifai\n</code></pre> - The first command will check the status of the classifai service. - The second command will restart the classifai service. - The third command will show the logs of the classifai service.</p>"},{"location":"developer/#run-the-flask-server-without-service","title":"Run the Flask server without service","text":"<pre><code># from classifAI-engine/\nsudo systemctl stop classifai # stop the service\nsource PATH_TO_VENV/bin/activate # try venv-3.10\npython3 src/app.py\n</code></pre>"},{"location":"developer/#run-the-gemma-server-without-service","title":"Run the GEMMA server without service","text":"<pre><code># from gemma-classification-1\nsudo systemctl stop gemma # stop the service\nsource PATH_TO_VENV/bin/activate # try .venv\n# do other installation steps if needed (see gemma README.md)\npython3 src/app.py\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10 or higher</li> <li>Docker is required to run this project. You can download it here.</li> <li>ffmpeg is required to run this project. You can download it here.</li> <li>Redis is required to run this project. You can download it with <code>sudo apt install redis</code>.</li> <li>Hugging Face token is required to use the Hugging Face models. You can get a token here. You must also accept the terms and conditions for the models you want to use (here and here).</li> </ul>"},{"location":"installation/#installation_1","title":"Installation","text":"<ol> <li>Clone the repo</li> </ol> <pre><code>git clone https://github.com/TCU-ClassifAI/classifAI-engine.git\ncd classifAI-engine\n</code></pre> <ol> <li>Install Python packages (it is recommended to use a virtual environment)</li> </ol> <pre><code>pip install -r src/requirements.txt\n</code></pre> <ol> <li>Install required system packages </li> </ol> <p><pre><code># Install ffmpeg\nsudo apt install ffmpeg # Ubuntu\nbrew install ffmpeg # MacOS\n# install Redis\nsudo apt install redis-server # Ubuntu\nbrew install redis # MacOS\n# start Redis\nsudo redis-server # Ubuntu\n</code></pre> 4. Accept the Hugging Face terms and conditions - 1. visit hf.co/pyannote/speaker-diarization-3.1 and accept user conditions - 2. visit hf.co/pyannote/segmentation-3.0 and accept user conditions - 3. visit hf.co/settings/tokens to create an access token</p> <ol> <li> <p>Set up the environment variables</p> </li> <li> <p>For a full list of environment variables, see the Configuration documentation. This guide will cover a minimal set of environment variables to get the server running.</p> </li> <li> <p>Create a <code>.env</code> file in the root directory of the project. The <code>.env</code> file should contain the following environment variables:</p> </li> </ol> <p><pre><code># .env\nHF_TOKEN=your_hugging_face_token # Get a token from https://hf.co/settings/tokens\nREDIS_PORT=6379 #(default port for Redis, can be changed), the URL can also be changed (see config)\nLLAMA_API_URL=http://localhost:5003 # URL for the LLAMA API\n</code></pre> 5. (Optional) Set up configuration for the API</p> <ul> <li> <p>Edit values in <code>src/config/config.py</code> to match your environment.</p> </li> <li> <p>Launch the API</p> </li> </ul> <pre><code>python src/app.py\n</code></pre> <ol> <li>Run your RQ worker (you can do this through supervisor or another process manager)</li> </ol> <pre><code>rq worker -c config.worker_config\n</code></pre>"},{"location":"installation/#test","title":"Test","text":"<p><code>curl http://localhost:5000/healthcheck</code> should return <code>OK</code></p> <p>More usage can be found in the API Documentation.</p>"},{"location":"installation/#installation-on-the-gpu-server","title":"Installation on the GPU Server","text":"<p>Currently, it is run as a Systemd service. The service file is located at <code>/etc/systemd/system/classifai.service</code>. The service can be started, stopped, and restarted using the following commands:</p> <pre><code>sudo systemctl start classifai\nsudo systemctl stop classifai\nsudo systemctl restart classifai\n</code></pre> <p>The logs can be viewed using the following command:</p> <pre><code>sudo journalctl -u classifai\n</code></pre>"},{"location":"pull_request_template/","title":"Pull request template","text":""},{"location":"pull_request_template/#type-of-change","title":"Type of Change","text":"<p>(Bug fix, new feature, documentation, configuration update, etc.)</p>"},{"location":"pull_request_template/#context","title":"Context","text":"<p>[Insert the issue number or link to the related issue, if applicable]</p>"},{"location":"pull_request_template/#changes-made","title":"Changes Made","text":"<ul> <li>[Insert a bullet point list of the changes made in this pull request]</li> </ul>"},{"location":"pull_request_template/#screenshots-and-testing","title":"Screenshots and Testing","text":"<p>[Insert any relevant screenshots, if applicable]</p>"},{"location":"pull_request_template/#checklist","title":"Checklist","text":"<ul> <li>[ ] I have tested these changes locally</li> <li>[ ] My code follows the style guidelines of this project</li> <li>[ ] I have performed a self-review of my own code</li> <li>[ ] I have commented my code, particularly in hard-to-understand areas</li> <li>[ ] I have updated the documentation, if applicable</li> <li>[ ] I have added unit tests, if applicable</li> </ul>"},{"location":"structure/","title":"Project Structure","text":""},{"location":"structure/#directory-structure-of-the-engine","title":"Directory Structure of the Engine","text":""},{"location":"structure/#this-engine-runs-on-flask-celery-and-redis","title":"This Engine runs on Flask, Celery, and Redis.","text":"<p>In order to be modular, we use Flask Blueprints to organize our code. </p> <pre><code>C: ClassifAI-engine\n\u251c\u2500\u2500\u2500.github\n\u2502   \u2514\u2500\u2500\u2500workflows # Github Actions for CI/CD. Includes automated testing and deployment.\n\u251c\u2500\u2500\u2500docs # Folder for documentation. Uses mkdocs.\n\u2502   \u251c\u2500\u2500\u2500assets\n\u2502   \u251c\u2500\u2500\u2500contribution\n\u2502   \u2514\u2500\u2500\u2500 # Documentation files. See docs/contribution/editing_docs.md for more information.\n\u2514\u2500\u2500\u2500src\n    \u251c\u2500\u2500\u2500app.py # main file, this imports the services and runs the engine\n\u251c\u2500\u2500\u2500utils # services that the engine provides. \n\u251c\u2500\u2500\u2500transcription # Contains the transcription service\n\u251c\u2500\u2500\u2500classification # Contains the classification service\n\u2514\u2500\u2500\u2500summarize # Contains the summarization service\n\u251c\u2500\u2500\u2500endpoints # Contains the API endpoints for the engine\n\u251c\u2500\u2500\u2500config # settings for the engine (development, production, etc.)\n\u251c\u2500\u2500\u2500requirements.txt and requirements-dev.txt # Python dependencies\n\u2514\u2500\u2500\u2500tests # Test suite\n</code></pre>"},{"location":"structure/#structure-of-the-services-folder","title":"Structure of the 'services' folder","text":"<pre><code>C: services\n\u251c\u2500\u2500\u2500transcription # Contains the transcription service\n\u2502   \u251c\u2500\u2500\u2500views.py # Contains the API for the transcription service (endpoints)\n\u2502   \u251c\u2500\u2500\u2500tasks.py # Config for task queueing of the transcription service (Celery)\n\u2502   \u2514\u2500\u2500\u2500validate.py # Validates the input for the transcription service\n\u251c\u2500\u2500\u2500 classification # Contains the classification service\n\u2502   \u251c\u2500\u2500\u2500views.py # Contains the API for the classification service (endpoints)\n\u2502   \u251c\u2500\u2500\u2500 # TODO: Add Utils\n\u2502   \u2514\u2500\u2500\u2500 # TODO: Add Tasks and Validation\n\u251c\u2500\u2500\u2500sentiment # Contains the sentiment service\n\u2502   \u251c\u2500\u2500\u2500views.py # Contains the API for the sentiment service (endpoints)\n\u2502   \u251c\u2500\u2500\u2500tasks # Contains the tasks for the sentiment service\n\u2502   \u2514\u2500\u2500\u2500utils # Contains the utils for the sentiment service\n\u251c\u2500\u2500\u2500summarize # Contains the summarization service\n\u2502   \u251c\u2500\u2500\u2500views.py # Contains the API for the summarization service (endpoints)\n\u2502   \u251c\u2500\u2500\u2500validate.py # Validates the input for the summarization service\n\u2502   \u2514\u2500\u2500\u2500utils.py # Contains the utils for the summarization service\n</code></pre>"},{"location":"structure/#other-files","title":"Other Files","text":"<p>There are also a few other files that are not included in the above tree. These are:</p> <ul> <li>.pre-commit-config.yaml - Configuration for pre-commit hooks</li> <li>mkdocs.yml - Configuration for mkdocs (documentation)</li> <li>Dockerfile - Dockerfile for building the engine # TODO: Add Dockerfile</li> <li>.gitignore - Files to ignore in git</li> </ul>"},{"location":"structure/#engine-architecture","title":"Engine Architecture","text":"<p>The engine is built using Flask, Celery, and Redis. The engine is deployed using Docker and Docker Compose.</p> <p>There are two main components of the engine: the API and the worker. The API is the main entry point for the engine. It is responsible for handling requests and sending them to the worker. The worker is responsible for processing the requests. The worker is also responsible for sending the results back to the API.</p> <p>The API and the worker are connected using Redis. Redis is a key-value store that is used as a message broker. The API and the worker communicate using Redis queues. The API pushes requests to the queue and the worker pops requests from the queue. The worker then processes the request and pushes the results to the queue. The API then pops the results from the queue and sends them back to the user.</p>"},{"location":"structure/#engine-connection-to-the-client-machine-classifai-portal","title":"Engine Connection to the Client Machine (ClassifAI Portal)","text":"<p>The engine functions as a RESTful API. The API is the main entry point for the engine. The API is responsible for handling requests and sending them to the worker. The worker is responsible for processing the requests. The worker is also responsible for sending the results back to the API.</p> <ul> <li>Both the client and engine share a database. This is so we are not passing over entire audio files to the engine. Instead, we pass over the file path to the audio file. The engine then reads the file from the database. This is more efficient than passing over the entire audio file.</li> </ul> <p>For expectations of the API, check out the API Documentation.</p>"},{"location":"transcription/","title":"Jobs: Transcription","text":"<p>Transcription is done by the transcription worker. The worker uses the whisper library to transcribe audio files, and NeMo to diarize and align the transcription to the audio.</p>"},{"location":"transcription/#transcription-format","title":"Transcription format","text":"<p>Recall that you can check the status of a job by sending a GET request to <code>get_transcription_status</code> with the <code>job_id</code> as a query parameter, like so:</p> <pre><code>curl http://localhost:5000/transcription/get_transcription_status?job_id=3c73dd07-66ff-48ab-9f4e-e6726987c06f\n</code></pre> <p>A job status will look like this:</p> <pre><code>{\n\"meta\": {\n\"job_id\": \"3c73dd07-66ff-48ab-9f4e-e6726987c06f\",\n\"job_type\": \"transcription\",\n\"message\": \"Aligning audio\",\n\"status\": \"aligning\"\n},\n\"status\": \"started\"\n}\n</code></pre> <p>When the job is completed, the status will look like this:</p> <pre><code>{\n\"meta\": {\n\"job_id\": \"3c73dd07-66ff-48ab-9f4e-e6726987c06f\",\n\"job_type\": \"transcription\",\n\"message\": \"Transcription and diarization completed\",\n\"status\": \"completed\"\n},\n\"result\": \"{\\\"job_id\\\": \\\"3c73dd07-66ff-48ab-9f4e-e6726987c06f\\\", \\\"type\\\": \\\"transcription\\\", \\\"status\\\": \\\"completed\\\", \\\"submit_time\\\": 1710546893.69, \\\"duration\\\": 0, \\\"result\\\": \\\"[{'speaker': 'Speaker 1', 'start_time': 7900, 'end_time': 11700, 'text': \\\\\\\"Our next guest is a true American hero, and he's only eight years old. \\\\\\\"}, {'speaker': 'Speaker 2', 'start_time': 12181, 'end_time': 19684, 'text': \\\\\\\"Last week, Lucas Armitage bravely defended his family and his home when he stopped an intruder all by himself just by using his daddy's gun. \\\\\\\"}, {'speaker': 'Speaker 1', 'start_time': 19704, 'end_time': 23125, 'text': \\\\\\\"That's right, and Lucas and his dad, Jack, are with us in the studio this morning. \\\\\\\"}, {'speaker': 'Speaker 1', 'start_time': 23165, 'end_time': 24226, 'text': 'Good morning to both of you. '}, {'speaker': 'Speaker 1', 'start_time': 24246, 'end_time': 25286, 'text': 'Hi, guys. '}, {'speaker': 'Speaker 1', 'start_time': 25326, 'end_time': 27047, 'text': 'Now, Lucas, can you tell us what happened? '}, {'speaker': 'Speaker 0', 'start_time': 27592, 'end_time': 31094, 'text': 'I heard the noise, and I got up from bed and went into the kitchen door. '}, {'speaker': 'Speaker 2', 'start_time': 31114, 'end_time': 31915, 'text': 'Dad keeps the gun. '}, {'speaker': 'Speaker 1', 'start_time': 32115, 'end_time': 34216, 'text': 'So you found it all by yourself, right? '}, {'speaker': 'Speaker 0', 'start_time': 34416, 'end_time': 35377, 'text': 'I take it out a lot. '}, {'speaker': 'Speaker 0', 'start_time': 35577, 'end_time': 36658, 'text': 'Sometimes I just look at it. '}, {'speaker': 'Speaker 1', 'start_time': 36758, 'end_time': 36938, 'text': 'Right. '}, {'speaker': 'Speaker 1', 'start_time': 36978, 'end_time': 39640, 'text': \\\\\\\"Now, it was a burglar, wasn't it, Lucas? \\\\\\\"}, {'speaker': 'Speaker 1', 'start_time': 39660, 'end_time': 41041, 'text': 'He was trying to steal things. '}, {'speaker': 'Speaker 0', 'start_time': 41201, 'end_time': 41901, 'text': 'He looked hungry. '}, {'speaker': 'Speaker 0', 'start_time': 42121, 'end_time': 45784, 'text': \\\\\\\"When he saw I had the gun, he put his hands up and said, please don't shoot. \\\\\\\"}, {'speaker': 'Speaker 1', 'start_time': 45924, 'end_time': 47885, 'text': \\\\\\\"But you didn't listen to him, did you? \\\\\\\"}, {'speaker': 'Speaker 0', 'start_time': 47905, 'end_time': 49606, 'text': 'I know it would be easy to shoot him. '}, {'speaker': 'Speaker 0', 'start_time': 49646, 'end_time': 50907, 'text': 'Just aim and pull the trigger. '}, {'speaker': 'Speaker 2', 'start_time': 51407, 'end_time': 51767, 'text': \\\\\\\"That's right. \\\\\\\"}, {'speaker': 'Speaker 2', 'start_time': 51787, 'end_time': 53768, 'text': \\\\\\\"Well, and that's exactly what you did, right? \\\\\\\"}, {'speaker': 'Speaker 1', 'start_time': 53808, 'end_time': 54928, 'text': \\\\\\\"You shot him in the leg, didn't you? \\\\\\\"}, {'speaker': 'Speaker 1', 'start_time': 54948, 'end_time': 56688, 'text': 'You put one right through the kneecap, right? '}, {'speaker': 'Speaker 0', 'start_time': 56708, 'end_time': 61410, 'text': 'Yeah, it was like bang, really loud, and he fell down screaming, and there was lots of blood coming out. '}, {'speaker': 'Speaker 0', 'start_time': 61430, 'end_time': 62470, 'text': 'Lucas, you really are a hero. '}, {'speaker': 'Speaker 0', 'start_time': 62510, 'end_time': 65150, 'text': 'He started crawling away and crying, so I shot him in the back. '}, {'speaker': 'Speaker 1', 'start_time': 65191, 'end_time': 67471, 'text': 'Yeah, you must be so proud of your son, Jack. '}, {'speaker': 'Speaker 0', 'start_time': 67491, 'end_time': 70112, 'text': 'And then I stood over him and shot him like bang, bang. '}, {'speaker': 'Speaker 1', 'start_time': 70891, 'end_time': 74593, 'text': \\\\\\\"Well, that's one crook that's not gonna be breaking into anybody else's home, is he? \\\\\\\"}, {'speaker': 'Speaker 0', 'start_time': 74613, 'end_time': 74853, 'text': 'Yeah. '}, {'speaker': 'Speaker 0', 'start_time': 74973, 'end_time': 77134, 'text': \\\\\\\"He wouldn't stop talking, so then I shut his jaw. \\\\\\\"}, {'speaker': 'Speaker 0', 'start_time': 77254, 'end_time': 78815, 'text': \\\\\\\"Well, how'd you manage to do that, Lucas? \\\\\\\"}, {'speaker': 'Speaker 0', 'start_time': 78975, 'end_time': 82737, 'text': 'Either you shoot at the temples and pull down, or you shoot at the side of the skull wall. '}, {'speaker': 'Speaker 3', 'start_time': 82817, 'end_time': 84278, 'text': \\\\\\\"It's the weakest part of the skull, he's right. \\\\\\\"}, {'speaker': 'Speaker 1', 'start_time': 84338, 'end_time': 86299, 'text': \\\\\\\"That's very sophisticated knowledge there. \\\\\\\"}, {'speaker': 'Speaker 0', 'start_time': 86519, 'end_time': 88300, 'text': 'Yeah, but then he started screaming. '}, {'speaker': 'Speaker 0', 'start_time': 88480, 'end_time': 89021, 'text': 'Yeah, right. '}, {'speaker': 'Speaker 0', 'start_time': 89061, 'end_time': 92043, 'text': 'And then I showed off each one of his fingers, and then he stopped screaming. '}, {'speaker': 'Speaker 2', 'start_time': 92063, 'end_time': 95805, 'text': 'So, Jack, it was the screaming you heard that woke you up so you could call the police? '}, {'speaker': 'Speaker 3', 'start_time': 95825, 'end_time': 96185, 'text': 'No, no. '}, {'speaker': 'Speaker 3', 'start_time': 96265, 'end_time': 98807, 'text': 'Actually, it was Lucas laughing that woke me up. '}, {'speaker': 'Speaker 3', 'start_time': 98907, 'end_time': 100628, 'text': 'I had never heard the kid laugh so hard. '}, {'speaker': 'Speaker 0', 'start_time': 100668, 'end_time': 101889, 'text': 'There was blood all over me. '}, {'speaker': 'Speaker 3', 'start_time': 102089, 'end_time': 103970, 'text': 'Yeah, he smeared it all over himself. '}, {'speaker': 'Speaker 3', 'start_time': 104050, 'end_time': 104471, 'text': 'Really? '}, {'speaker': 'Speaker 0', 'start_time': 104511, 'end_time': 106632, 'text': 'I liked the way the blood made me feel. '}, {'speaker': 'Speaker 1', 'start_time': 106672, 'end_time': 109674, 'text': 'Now, your school gave you a special award for courage, right? '}, {'speaker': 'Speaker 1', 'start_time': 109794, 'end_time': 111915, 'text': 'We have a photograph of that award ceremony. '}, {'speaker': 'Speaker 2', 'start_time': 111935, 'end_time': 112556, 'text': \\\\\\\"Let's take a look. \\\\\\\"}, {'speaker': 'Speaker 3', 'start_time': 112856, 'end_time': 116197, 'text': \\\\\\\"Oh, Lucas, you didn't even change your shirt before you got your award. \\\\\\\"}, {'speaker': 'Speaker 3', 'start_time': 116217, 'end_time': 117237, 'text': 'Well, why would he change his shirt? '}, {'speaker': 'Speaker 3', 'start_time': 117257, 'end_time': 118037, 'text': \\\\\\\"That's his honor shirt. \\\\\\\"}, {'speaker': 'Speaker 0', 'start_time': 118137, 'end_time': 119017, 'text': 'I want the blood. '}, {'speaker': 'Speaker 1', 'start_time': 119117, 'end_time': 122278, 'text': 'Yeah, it must have been fun getting that award at school, right? '}, {'speaker': 'Speaker 0', 'start_time': 122298, 'end_time': 123298, 'text': 'I want the blood. '}, {'speaker': 'Speaker 1', 'start_time': 125038, 'end_time': 127999, 'text': \\\\\\\"Well, he's gotten a little shy now. \\\\\\\"}, {'speaker': 'Speaker 2', 'start_time': 128318, 'end_time': 130439, 'text': 'Well, Jack Armitage, thanks so much for being here. '}, {'speaker': 'Speaker 2', 'start_time': 130499, 'end_time': 132160, 'text': 'Lucas, thank you for your heroic work. '}, {'speaker': 'Speaker 1', 'start_time': 132320, 'end_time': 133040, 'text': 'Absolutely. '}, {'speaker': 'Speaker 1', 'start_time': 133080, 'end_time': 138221, 'text': 'Now you stick with us because after the break, some warning signs that your pet may be a CIA mole. '}]\\\", \\\"job_info\\\": \\\"{\\\\\\\"audio_path\\\\\\\": \\\\\\\"output/test.mp3\\\\\\\", \\\\\\\"model_id\\\\\\\": null}\\\"}\",\n\"status\": \"finished\"\n}\n</code></pre>"},{"location":"transcription/#status-messages-and-their-meanings","title":"Status Messages and their meanings","text":""},{"location":"transcription/#once-a-job-is-started-the-status-will-be-started-the-meta-object-will-contain-the-job_id-job_type-message-and-status","title":"Once a job is started, the status will be <code>started</code>. The <code>meta</code> object will contain the <code>job_id</code>, <code>job_type</code>, <code>message</code>, and <code>status</code>.","text":"<p>The different statuses, and their respective messages within the <code>meta</code> object are, in order:</p> <ol> <li>queued</li> <li>\"Job is queued\"</li> <li>downloading<ul> <li>\"Downloading MP3 file from URL\"</li> <li>Note: This status is only applicable if the audio file is being downloaded from a URL.</li> </ul> </li> <li>start_transcribing<ul> <li>\"Transcribing audio\"</li> </ul> </li> <li>splitting<ul> <li>\"Splitting audio into vocals and accompaniment for faster processing\"</li> </ul> </li> <li>loading_nemo<ul> <li>\"Loading NeMo process for diarization\"</li> </ul> </li> <li>transcribing<ul> <li>\"Transcribing audio with Whisper\"</li> </ul> </li> <li>loading_align_model<ul> <li>\"Loading align model\"</li> </ul> </li> <li>aligning<ul> <li>\"Aligning audio\"</li> </ul> </li> <li>diarizing<ul> <li>\"Diarizing audio\"</li> <li>Note: Diarization happens in parallel with transcription. This only shows if transcription is completed before diarization.</li> </ul> </li> <li>transcription_finished<ul> <li>\"Transcription completed\"</li> </ul> </li> <li>extracting_questions<ul> <li>\"Extracting questions\"</li> </ul> </li> <li>categorizing_questions<ul> <li>\"Categorizing questions using LLaMA\"</li> </ul> </li> <li>summarizing<ul> <li>\"Summarizing the transcription\"</li> </ul> </li> <li>combining_results<ul> <li>\"Combining results\"</li> </ul> </li> <li>completed<ul> <li>\"Transcription and diarization completed\"</li> </ul> </li> </ol> <p>Other possible statuses are: failed error</p>"},{"location":"transcription/#once-a-job-is-completed-the-status-will-be-finished-the-meta-object-will-contain-the-job_id-job_type-message-and-status-and-the-result-object-will-contain-the-job_id-type-status-submit_time-duration-result-and-job_info","title":"Once a job is completed, the status will be <code>finished</code>. The <code>meta</code> object will contain the <code>job_id</code>, <code>job_type</code>, <code>message</code>, and <code>status</code>, and the <code>result</code> object will contain the <code>job_id</code>, <code>type</code>, <code>status</code>, <code>submit_time</code>, <code>duration</code>, <code>result</code>, and <code>job_info</code>.","text":"<p>If an error occurs, the status will be <code>error</code>, and the <code>message</code> will be:</p> <pre><code>\"An error occured: {error message}\"\n</code></pre>"},{"location":"about/about/","title":"About","text":"<p>Hi there! This is the documentation for the ClassifAI engine. This is a RESTful API that provides the heavy lifting for classifAI through audio transcription, question categorization, and insights.</p>"},{"location":"about/about/#built-with","title":"Built With","text":"<ul> <li>Python</li> <li>Flask</li> <li>OpenAI</li> <li>PyTorch</li> <li>Celery</li> <li>Redis</li> <li>MongoDB</li> <li>Pydantic</li> <li>Docker</li> <li>Docker Compose</li> <li>MkDocs</li> <li>GitHub Actions</li> </ul> <p>We are cool and use shields.io for our badges.</p> <p>About the Team</p> <p>This project was created by the ClassifAI team. We are a group of students at Texas Christian University who are passionate about using AI for good.</p> <p>We are currently working on this project as part of our senior capstone project. We are advised by Dr. Bingyang Wei and Dr. [Liran Ma](</p>"},{"location":"about/changelog/","title":"Change Log","text":"<p>All notable changes to this project will be documented in this file.</p>"},{"location":"about/changelog/#unreleased-yyyy-mm-dd","title":"[Unreleased] - yyyy-mm-dd","text":"<p>Here we write upgrading notes for brands. It's a team effort to make them as straightforward as possible.</p>"},{"location":"about/changelog/#added","title":"Added","text":""},{"location":"about/changelog/#changed","title":"Changed","text":""},{"location":"about/changelog/#fixed","title":"Fixed","text":""},{"location":"about/changelog/#100-31-oct-2023","title":"[1.0.0] - 31 Oct 2023","text":""},{"location":"about/changelog/#added_1","title":"Added","text":"<ul> <li>Transcription using Whisper is now available.</li> </ul>"},{"location":"about/changelog/#changed_1","title":"Changed","text":""},{"location":"about/changelog/#fixed_1","title":"Fixed","text":""},{"location":"api/api/","title":"API Reference","text":"<p>This API is split into two parts: Transcription and Classification.</p>"},{"location":"api/api_analyze/","title":"Analyze an audio file","text":"<p>This endpoint kicks off an analysis job. It returns a job ID that can be used to check the status of the analysis job.</p>"},{"location":"api/api_analyze/#start-an-analysis","title":"Start an Analysis","text":""},{"location":"api/api_analyze/#http-method-and-url","title":"HTTP Method and URL","text":"<p><code>POST https://llm.cs.tcu.edu:5000/analyze/</code></p>"},{"location":"api/api_analyze/#parameters","title":"Parameters","text":"<p>EITHER - file: The audio file to be analyzed. This is a local file that is uploaded to the server. OR - url: The URL of the audio file to be analyzed. This is a file that is accessible via a URL.</p> Name Type Description Required? file file The audio file to be analyzed. This is a local file that is uploaded to the server. Required if <code>url</code> is not provided url string The URL of the audio file to be analyzed. This is a file that is accessible via a URL. Required if <code>file</code> is not provided model_name string The name of the model to use for analysis. Default is (large-v3) (can edit in config) Optional"},{"location":"api/api_analyze/#example-request","title":"Example Request","text":"<pre><code>{\n\"file\": \"path/to/audio/file\",\n\"model_name\": \"large-v3\"\n}\n</code></pre> <pre><code>curl -X POST -H \"Content-Type: application/json\" -d '{\"url\": \"https://www.youtube.com/watch?v=t4yWEt0OSpg\"}' http://llm.cs.tcu.edu:5000/analyze\n</code></pre>"},{"location":"api/api_analyze/#example-response","title":"Example Response","text":"<pre><code>{\n\"job_id\":\"73f22806-d904-448f-ae84-650bf6f5aa6a\",\n\"message\":\"Job enqueued\"\n}\n</code></pre>"},{"location":"api/api_analyze/#get-analysis-status","title":"Get Analysis Status","text":""},{"location":"api/api_analyze/#get-analysis-status_1","title":"Get Analysis Status","text":"<p>This endpoint returns the status of an analysis job. It can be used to check the status of an analysis job, or to get the analysis results.</p>"},{"location":"api/api_analyze/#http-method-and-url_1","title":"HTTP Method and URL","text":"<p><code>GET https://llm.cs.tcu.edu:5000/analyze?job_id=[INSERT_JOB_ID]</code></p>"},{"location":"api/api_analyze/#parameters_1","title":"Parameters","text":"Name Type Description Required? job_id string The job ID of the analysis job. Required"},{"location":"api/api_analyze/#example-request_1","title":"Example Request","text":"<pre><code>curl -X GET http://llm.cs.tcu.edu:5000/analyze?job_id=73f22806-d904-448f-ae84-650bf6f5aa6a\n</code></pre>"},{"location":"api/api_analyze/#example-response_1","title":"Example Response","text":"<p><pre><code>{\n\"meta\": {\n\"job_id\": \"e8017039-8a41-480e-b80f-3cb5233611a9\",\n\"job_type\": \"analyze\",\n\"message\": \"Downloading YouTube and converting to mp3\",\n\"progress\": \"downloading\",\n\"title\": \"Asking Questions in English | Question Structure | Fix Your Grammar Mistakes!\"\n},\n\"status\": \"started\"\n}\n</code></pre> (Note: The title field will only update once the video has been downloaded, if it is a YouTube video. Otherwise, it will be the audio file name.)</p>"},{"location":"api/api_analyze/#final-analysis-results","title":"Final Analysis Results","text":"<p>A full response can be found at this pastebin link.</p> <p>Here is a snippet of the response:</p> <pre><code>{\n\"meta\": {\n\"job_id\": \"73f22806-d904-448f-ae84-650bf6f5aa6a\",\n\"job_type\": \"analyze\",\n\"message\": \"Analysis completed\",\n\"progress\": \"completed\",\n\"title\": \"The title of the video\",\n},\n\"result\": {\n\"questions\": [\n{\n\"question\": \"What is the title of the video?\",\n\"level\": 1,\n\"speaker\": \"Main Speaker\",\n\"start_time\": 25034,\n\"end_time\": 26324,\n},\n{\n\"question\": \"What is the video about?\",\n\"level\": 1,\n\"speaker\": \"Main Speaker\",\n\"start_time\": 26324,\n\"end_time\": 27534,\n}\n],\n\"summary\": \"One or two sentences summarizing the video\",\n\"transcript\": [\n{\n\"speaker\": \"Main Speaker\",\n\"start_time\": 0,\n\"end_time\": 1000,\n\"text\": \"The first sentence of the transcript.\"\n},\n{\n\"speaker\": \"Main Speaker\",\n\"start_time\": 1000,\n\"end_time\": 2000,\n\"text\": \"The second sentence of the transcript.\"\n}\n]\n},\n\"status\": \"finished\",\n}\n</code></pre>"},{"location":"api/api_classification/","title":"API Reference","text":"<p>API KEY INSTRUCTIONS</p> <p>Ensure that you include your API key in all requests by using the following format: curl -H \"X-API-KEY: MYAPIKEY\" https://api.mydomain.com/v1/users. Need an API key or instructions on how to obtain one?</p>"},{"location":"api/api_classification/#categorization","title":"Categorization","text":""},{"location":"api/api_classification/#categorize_transcript","title":"categorize_transcript","text":"<ul> <li> <p>URL: <code>/categorize/categorize_transcript</code></p> </li> <li> <p>Method: <code>POST</code></p> </li> <li> <p>Data Params:   JSON array of objects with the following fields:</p> </li> <li><code>end_time</code> (int)</li> <li><code>speaker</code> (string)</li> <li><code>start_time</code> (int)</li> <li> <p><code>text</code> (string)</p> </li> <li> <p>Success Response:</p> </li> <li>Code: 200 OK</li> <li>Content: <pre><code>[\n{\n\"end_time\": 2301,\n\"level\": 1,\n\"question\": \"Why did you bring me here? \",\n\"speaker\": \"Speaker 0\",\n\"start_time\": 1260,\n}\n]\n</code></pre></li> </ul>"},{"location":"api/api_classification/#examples","title":"EXAMPLES:","text":"<p>CURL:  <pre><code>curl -X POST -H \"Content-Type: application/json\"      -d '[\n{\n\"end_time\": 2301,\n\"speaker\": \"Speaker 0\",\n\"start_time\": 1260,\n\"text\": \"Why did you bring me here? \"\n},\n{\n\"end_time\": 4263,\n\"speaker\": \"Main Speaker\",\n\"start_time\": 3242,\n\"text\": \"I dont like going out. \"\n}\n]' localhost:5000/categorize/categorize_transcript\n</code></pre> RESPONSE:</p> <pre><code>[\n{\n\"end_time\": 2301,\n\"level\": 1,\n\"question\": \"Why did you bring me here? \",\n\"speaker\": \"Speaker 0\",\n\"start_time\": 1260,\n}\n]\n</code></pre>"},{"location":"api/api_key/","title":"Get an API Key","text":"<p>To get an API key, please contact the ClassifAI team at http://classifai.tcu.edu/contact/.</p>"},{"location":"api/api_server_info/","title":"Server Information Routes","text":""},{"location":"api/api_server_info/#get-server-information","title":"Get Server Information","text":""},{"location":"api/api_server_info/#default-route","title":"Default Route","text":""},{"location":"api/api_server_info/#http-method-and-url","title":"HTTP Method and URL","text":"<p><code>GET http://llm.cs.tcu.edu:5000/</code></p>"},{"location":"api/api_server_info/#parameters","title":"Parameters","text":"<p>None</p>"},{"location":"api/api_server_info/#example-request","title":"Example Request","text":"<pre><code>curl http://llm.cs.tcu.edu:5000/\n</code></pre>"},{"location":"api/api_server_info/#example-response","title":"Example Response","text":"<pre><code>&lt;h1&gt;ClassifAI Engine&lt;/h1&gt;&lt;p&gt;Version: 3.0.3&lt;/p&gt;&lt;p&gt;Environment: dev&lt;/p&gt;&lt;p&gt;Healthcheck: OK&lt;/p&gt;&lt;a href='https://tcu-classifai.github.io/classifAI-engine/'&gt;Documentation&lt;/a&gt;\n</code></pre>"},{"location":"api/api_server_info/#healthcheck-route","title":"Healthcheck Route","text":""},{"location":"api/api_server_info/#http-method-and-url_1","title":"HTTP Method and URL","text":"<p><code>GET http://llm.cs.tcu.edu:5000/healthcheck</code></p>"},{"location":"api/api_server_info/#parameters_1","title":"Parameters","text":"<p>None</p>"},{"location":"api/api_server_info/#example-request_1","title":"Example Request","text":"<pre><code>curl http://llm.cs.tcu.edu:5000/healthcheck\n</code></pre>"},{"location":"api/api_server_info/#example-response_1","title":"Example Response","text":"<pre><code>OK\n</code></pre>"},{"location":"api/api_server_info/#config","title":"Config","text":""},{"location":"api/api_server_info/#editing-config","title":"Editing Config","text":"<p>To edit the config, you can edit the <code>config.py</code> file in the <code>src/config</code> directory.</p> <p>Please see the config documentation for more information on the config file.</p>"},{"location":"api/api_server_info/#http-method-and-url_2","title":"HTTP Method and URL","text":"<p><code>GET http://llm.cs.tcu.edu:5000/config</code></p>"},{"location":"api/api_server_info/#parameters_2","title":"Parameters","text":"<p>None</p>"},{"location":"api/api_server_info/#example-request_2","title":"Example Request","text":"<pre><code>curl http://llm.cs.tcu.edu:5000/config\n</code></pre>"},{"location":"api/api_server_info/#example-response_2","title":"Example Response","text":"<pre><code>{\n\"CATEGORIZATION_MODEL\": \"gemma\",\n\"ENV_TYPE\": \"dev\",\n\"SUMMARIZATION_MODEL\": \"huggingface\",\n\"TRANSCRIPTION_MODEL\": \"large-v3\",\n\"VERSION\": \"3.0.3\"\n}\n</code></pre>"},{"location":"api/api_server_info/#authentication","title":"Authentication","text":""},{"location":"api/api_server_info/#test-authentication","title":"Test Authentication","text":""},{"location":"api/api_server_info/#http-method-and-url_3","title":"HTTP Method and URL","text":"<p><code>GET http://llm.cs.tcu.edu:5000/auth</code></p>"},{"location":"api/api_server_info/#parameters_3","title":"Parameters","text":"<p>Must include an API key in the header.</p>"},{"location":"api/api_server_info/#example-request_3","title":"Example Request","text":"<pre><code>curl -H \"X-API-KEY: MYAPIKEY\" http://llm.cs.tcu.edu:5000/auth\n</code></pre>"},{"location":"api/api_server_info/#example-response_3","title":"Example Response","text":"<p>Success:</p> <pre><code>OK, 200\n</code></pre> <p>Failure:</p> <p><pre><code>{\n\"message\": \"Unauthorized. Pleae add a header with the key API-Key and your secret key.\"\n}\n</code></pre> 401</p>"},{"location":"api/api_summarization/","title":"API Reference","text":"<p>API KEY INSTRUCTIONS</p> <p>Ensure that you include your API key in all requests by using the following format: curl -H \"X-API-KEY: MYAPIKEY\" https://api.mydomain.com/v1/users. Need an API key or instructions on how to obtain one?</p>"},{"location":"api/api_summarization/#start-a-transcription","title":"Start a Transcription","text":"<p>This endpoint kicks off a transcription job. It returns a job ID that can be used to check the status of the transcription job.</p>"},{"location":"api/api_summarization/#http-method-and-url","title":"HTTP Method and URL","text":"<p><code>POST https://api.classifai.tcu.edu/start_transcription</code></p>"},{"location":"api/api_summarization/#parameters","title":"Parameters","text":"Name Type Description Required? file file This is the audio file. It can be in mp3, wav, etc. FFMpeg supports many file types Required user_id string This is the user ID. It is used to identify the user that made the reqeust Optional model_type string Model Type. Can be \"large\", \"medium\", \"medium.en\", \"tiny.en\", more here Optional"},{"location":"api/api_summarization/#example-request","title":"Example Request","text":""},{"location":"api/api_summarization/#example-response","title":"Example Response","text":"<p>HTTP 200 OK</p> <pre><code>{\n\"job_id\": \"a3a8ed6e-f538-4a06-8fd2-4a3f3ff906ee\", \"model_type\": \"tiny.en\",\n\"status\": \"in progress\", \"state\": \"loading model\",\n\"start_time\": 1698877559.0479097,\n\"duration\": 0\n}\n</code></pre> Element Type Description job_id string This is the job ID, generated using UUID. It can be used to check the status of the transcription job. model_type string This is the model type. It can be \"large\", \"medium\", \"medium.en\", \"tiny.en\", more here status string This is the status of the transcription job. It can be \"in progress\", \"completed\", or \"error\" state string This is the state of the transcription job. It can be \"loading model\", \"loading audio\", \"transcribing\", \"uploading\", \"completed\", or \"error\" start_time float This is the start time of the transcription job. It is a Unix timestamp. duration float This is the duration of the transcription job. It is a Unix timestamp."},{"location":"api/api_summarization/#error-and-status-codes","title":"Error and Status Codes","text":"Code Message Meaning 400 No file provided The request did not include a file 400 Invalid file type The file type is not supported 400 Invalid model type The model type is not supported 400 Invalid user ID The user ID is not valid 500 Internal Server Error Something went wrong on our end. Please try again later."},{"location":"api/api_summarization/#get-transcription","title":"Get Transcription","text":"<p>This endpoint returns the status of a transcription job. It can be used to check the status of a transcription job, or to get the transcription file.</p>"},{"location":"api/api_summarization/#http-method-and-url_1","title":"HTTP Method and URL","text":"<p><code>GET https://api.classifai.tcu.edu/get_transcription</code></p>"},{"location":"api/api_summarization/#parameters_1","title":"Parameters","text":"<p>[Table that lists all query and path parameters for the endpoint. If this endpoint has query and path parameters, consider listing them in separate tables---one for path parameters, one for query parameters. If there aren't any parameters for this endpoint, replace the table with \"None\"]</p> Name Type Description Required? job_id string This is the job ID. It can be used to check the status of the transcription job, or to get the transcription file. Required"},{"location":"api/api_summarization/#example-request_1","title":"Example Request","text":"Element Type Description Required? job_id string This is the job ID. It can be used to check the status of the transcription job, or to get the transcription file. Required"},{"location":"api/api_summarization/#example-response_1","title":"Example Response","text":"<pre><code>{\n\"job_id\": \"a3a8ed6e-f538-4a06-8fd2-4a3f3ff906ee\",\n\"model_type\": \"tiny.en\", \"status\": \"in progress\", \"state\": \"loading model\", \"start_time\": 1698877559.0479097, \"duration\": 22.8137366771698\n}\n</code></pre> Element Type Description job_id string This is the job ID, generated using UUID. It can be used to check the status of the transcription job, or to get the transcription file. model_type string This is the model type. status string This is the status of the transcription job. It can be \"in progress\", \"completed\", \"not found\", or \"error\" state string This is the state of the transcription job. It can be \"loading model\", \"loading audio\", \"transcribing\", \"uploading\", \"completed\", or \"error\" start_time float This is the start time of the transcription job. It is a Unix timestamp. duration float This is the duration of the transcription job. It is a Unix timestamp. end_time float This is the end time of the transcription job (if it is completed). It is a Unix timestamp. transcription_link string This is the link to the transcription file (if it is completed). It can be used to download the transcription file. Looking for the transcription format?"},{"location":"api/api_summarization/#error-and-status-codes_1","title":"Error and Status Codes","text":"Code Message Meaning 400 No job ID provided The request did not include a job ID 404 Job not found The job ID provided does not match any transcription jobs. 500 Internal Server Error Something went wrong on our end. Please try again later."},{"location":"api/api_summarization/#remove-an-employee","title":"[Remove an employee]","text":"<p>[The heading above should be a very brief description of what the endpoint does.]</p>"},{"location":"api/api_summarization/#http-method-and-url_2","title":"HTTP Method and URL","text":"<p>[<code>GET</code>, <code>PUT</code>, <code>POST</code>, or <code>DELETE</code> and URL---for example, <code>DELETE https://api.payrollrecord.com/employee/{employee_id}</code>]</p>"},{"location":"api/api_summarization/#parameters_2","title":"Parameters","text":"<p>[Table that lists all query and path parameters for the endpoint. If this endpoint has query and path parameters, consider listing them in separate tables---one for path parameters, one for query parameters. If there aren't any parameters for this endpoint, replace the table with \"None\"]</p> Name Type Description Required? [Name or parameter] [Query or Path] [Brief description of parameter function. What does it do?] [Required or Optional] [Name or parameter] [Query or Path] [Brief description of parameter function. What does it do?] [Required or Optional] [Name or parameter] [Query or Path] [Brief description of parameter function. What does it do?] [Required or Optional]"},{"location":"api/api_summarization/#example-request_2","title":"Example Request","text":"<p>[Code or pseudocode sample of a complete request for this endpoint, including header and body, followed by a table that lists each element in the example request]</p> Element Type Description Required? [Element as it appears in request] [Array, Object, String, Integer, or Float] [Brief description of what information the element represents, including default and valid values] [Required or Optional] [Element as it appears in request] [Array, Object, String, Integer, or Float] [Brief description of what information the element represents, including default and valid values] [Required or Optional] [Element as it appears in request] [Array, Object, String, Integer, or Float] [Brief description of what information the element represents, including default and valid values] [Required or Optional]"},{"location":"api/api_summarization/#example-response_2","title":"Example Response","text":"<p>[Code or pseudocode sample of a complete response for this endpoint, followed by a table that lists each element in the example response]</p> Element Type Description `{\"job_id\": \"a3a8ed6e-f538-4a06-8fd2-4a3f3ff906ee\", \"model_type\": \"tiny.en\", \"status\": \"in progress\", \"state\": \"loading model\", \"start_time\": 1698877559.0479097, \"duration\": 22.8137366771698}` Object [Brief description of what information the element represents] `{\"job_id\": \"a3a8ed6e-f538-4a06-8fd2-4a3f3ff906ee\", \"model_type\": \"tiny.en\", \"status\": \"in progress\", \"state\": \"loading [Element as it appears in response] [Array, Object, String, Integer, or Float] [Brief description of what information the element represents] [Element as it appears in response] [Array, Object, String, Integer, or Float] [Brief description of what information the element represents] [Element as it appears in response] [Array, Object, String, Integer, or Float] [Brief description of what information the element represents]"},{"location":"api/api_summarization/#error-and-status-codes_2","title":"Error and Status Codes","text":"<p>[Table that lists all possible error and status codes for this endpoint]</p> Code Message Meaning [HTTP or error code] [Message for the code, such as \"Not Found\"] [Brief description of what the code means within your API, such as \"We couldn't complete your request right now\"] [HTTP or error code] [Message for the code, such as \"Not Found\"] [Brief description of what the code means within your API, such as \"We couldn't complete your request right now\"] [HTTP or error code] [Message for the code, such as \"Not Found\"] [Brief description of what the code means within your API, such as \"We couldn't complete your request right now\"]"},{"location":"api/api_transcription/","title":"API Reference - Transcription","text":"<p>API KEY INSTRUCTIONS</p> <p>Ensure that you include your API key in all requests by using the following format: curl -H \"X-API-KEY: MYAPIKEY\" https://api.mydomain.com/v1/users. Need an API key or instructions on how to obtain one?</p> <p>At the moment, the API key is not required. However, it will be required in the future. At the moment, you cannot access the HTTP API from outside the TCU network. However, everything is set up to work assuming you self-host the API.</p>"},{"location":"api/api_transcription/#starting-transcriptions","title":"Starting Transcriptions","text":""},{"location":"api/api_transcription/#start-a-transcription","title":"Start a Transcription","text":"<p>This endpoint kicks off a transcription job. It returns a job ID that can be used to check the status of the transcription job.</p>"},{"location":"api/api_transcription/#http-method-and-url","title":"HTTP Method and URL","text":"<p><code>POST https://llm.cs.tcu.edu:5000/transcription/transcribe</code></p>"},{"location":"api/api_transcription/#parameters","title":"Parameters","text":"Name Type Description Required? file file This is the audio file. It can be in mp3, wav, etc. FFMpeg supports many file types Required user_id string This is the user ID. It is used to identify the user that made the reqeust Optional model_type string Model Type. Can be \"large\", \"medium\", \"medium.en\", \"tiny.en\", more here Optional"},{"location":"api/api_transcription/#example-response","title":"Example Response","text":"<p>HTTP 200 OK</p> <pre><code>{\n\"job_id\":\"73f22806-d904-448f-ae84-650bf6f5aa6a\",\n\"message\":\"Job enqueued\"\n}\n</code></pre> Element Type Description job_id string This is the job ID, generated using UUID. It can be used to check the status of the transcription job. model_type string This is the model type. It can be \"large\", \"medium\", \"medium.en\", \"tiny.en\", more here status string This is the status of the transcription job. It can be \"in progress\", \"completed\", or \"error\" state string This is the state of the transcription job. It can be \"loading model\", \"loading audio\", \"transcribing\", \"uploading\", \"completed\", or \"error\" start_time float This is the start time of the transcription job. It is a Unix timestamp. duration float This is the duration of the transcription job. It is a Unix timestamp."},{"location":"api/api_transcription/#error-and-status-codes","title":"Error and Status Codes","text":"Code Message Meaning 400 No file provided The request did not include a file 400 Invalid file type The file type is not supported 400 Invalid model type The model type is not supported 400 Invalid user ID The user ID is not valid 500 Internal Server Error Something went wrong on our end. Please try again later."},{"location":"api/api_transcription/#start-a-youtube-transcription","title":"Start a YouTube Transcription","text":"<p>This endpoint kicks off a transcription job. It returns a job ID that can be used to check the status of the transcription job.</p>"},{"location":"api/api_transcription/#http-method-and-url_1","title":"HTTP Method and URL","text":"<p><code>POST https://llm.cs.tcu.edu:5000/transcription/transcribe_yt</code></p>"},{"location":"api/api_transcription/#get-transcriptions-status","title":"Get Transcriptions Status","text":""},{"location":"api/api_transcription/#get-transcription-status","title":"Get Transcription Status","text":"<p>This endpoint returns the status of a transcription job. It can be used to check the status of a transcription job, or to get the transcription file.</p>"},{"location":"api/api_transcription/#http-method-and-url_2","title":"HTTP Method and URL","text":"<p><code>GET https://llm.cs.tcu.edu:5000/transcription/get_transcription_status?job_id=[INSERT_JOB_ID]</code></p>"},{"location":"api/api_transcription/#parameters_1","title":"Parameters","text":"<p>[Table that lists all query and path parameters for the endpoint. If this endpoint has query and path parameters, consider listing them in separate tables---one for path parameters, one for query parameters. If there aren't any parameters for this endpoint, replace the table with \"None\"]</p> Name Type Description Required? job_id string This is the job ID. It can be used to check the status of the transcription job, or to get the transcription file. Required"},{"location":"api/api_transcription/#example-request","title":"Example Request","text":"Element Type Description Required? job_id string This is the job ID. It can be used to check the status of the transcription job, or to get the transcription file. Required"},{"location":"api/api_transcription/#example-response_1","title":"Example Response","text":"<pre><code>{\n\"job_id\": \"a3a8ed6e-f538-4a06-8fd2-4a3f3ff906ee\",\n\"model_type\": \"tiny.en\", \"status\": \"in progress\", \"state\": \"loading model\", \"start_time\": 1698877559.0479097, \"duration\": 22.8137366771698\n}\n</code></pre> Element Type Description job_id string This is the job ID, generated using UUID. It can be used to check the status of the transcription job, or to get the transcription file. model_type string This is the model type. status string This is the status of the transcription job. It can be \"in progress\", \"completed\", \"not found\", or \"error\" state string This is the state of the transcription job. It can be \"loading model\", \"loading audio\", \"transcribing\", \"uploading\", \"completed\", or \"error\" start_time float This is the start time of the transcription job. It is a Unix timestamp. duration float This is the duration of the transcription job. It is a Unix timestamp. end_time float This is the end time of the transcription job (if it is completed). It is a Unix timestamp. transcription_link string This is the link to the transcription file (if it is completed). It can be used to download the transcription file. Looking for the transcription format?"},{"location":"api/api_transcription/#error-and-status-codes_1","title":"Error and Status Codes","text":"Code Message Meaning 400 No job ID provided The request did not include a job ID 404 Job not found The job ID provided does not match any transcription jobs. 500 Internal Server Error Something went wrong on our end. Please try again later."},{"location":"api/api_yt/","title":"Api yt","text":""},{"location":"api/api_yt/#healthcheck","title":"Healthcheck","text":""},{"location":"contribution/contributing/","title":"Contribution","text":""},{"location":"contribution/contributing/#how-to-contribute","title":"How to Contribute","text":"<ol> <li>Fork the Project</li> <li>Create your Feature Branch (<code>git checkout -b feature/AmazingFeature</code>)</li> <li>Make your changes</li> <li>Run <code>pre-commit run --all-files</code> to run all hooks on all files. (See Pre-Commit Hooks for more information)</li> <li>Commit your Changes (<code>git commit -m 'Add some AmazingFeature'</code>)</li> <li>Push to the Branch (<code>git push origin feature/AmazingFeature</code>)</li> <li> <p>Open a Pull Request</p> </li> <li> <p>Pull requests must be reviewed by at least one other person before being merged.</p> </li> <li>Pull requests must pass all checks before being merged.</li> <li>If you have access to the slack channel, please post a link to your PR in the slack channel, that is the fastest way to get it reviewed.</li> </ol>"},{"location":"contribution/contributing/#workflow","title":"Workflow","text":"<p>Typically, you will make a feature branch off of <code>main</code> and make your changes there. When you are done, you will open a pull request to merge your feature branch into <code>main</code>.</p> <p>You can name your feature branch whatever you want, but it is recommended to use the following naming convention:</p> <p>either  * <code>feat/&lt;feature-name&gt;</code> * <code>bugfix/&lt;bug-name&gt;</code> * <code>hotfix/&lt;hotfix-name&gt;</code>  * <code>&lt;ticket-number&gt;/&lt;feature-name&gt;</code></p> <p>For example, if you are working on a feature to add a new endpoint to the transcription service, you could name your branch <code>feat/add-new-endpoint-to-transcription-service</code>.</p>"},{"location":"contribution/contributing/#specifications","title":"Specifications","text":"<ul> <li>Style Guide</li> <li>Instructions for Pre-Commit</li> </ul>"},{"location":"contribution/contributing/#editing-documentation","title":"Editing Documentation","text":"<ul> <li>Please see Editing Documentation for more information on how to edit this documentation! </li> </ul>"},{"location":"contribution/contributing/#raise-an-issue","title":"Raise an Issue","text":"<p>If you have a suggestion that would make this better, please fork the repo and create an issue. You can also simply open an issue with the tag \"enhancement\". We have templates for issues, so please use them!</p>"},{"location":"contribution/contributing/#reminders","title":"Reminders","text":"<ul> <li>Be sure to write tests for your code. These are within the <code>tests</code> directory.</li> <li>Your PR will not be merged if it does not pass all tests.</li> <li>Be sure to write docstrings for your code. </li> <li>You have to re-run <code>git add</code> after the pre-commit hook runs.</li> <li>Pull requests must be reviewed by at least one other person before being merged.</li> <li>Keep your PRs small and focused. If you have multiple changes, please make multiple PRs! This makes it easier to review and merge.</li> </ul>"},{"location":"contribution/editing_docs/","title":"Editing Documentation","text":"<p>This Documentation is built using MkDocs and Material for MkDocs</p> <p>For full documentation visit mkdocs.org and squidfunk.github.io/mkdocs-material</p>"},{"location":"contribution/editing_docs/#tldr","title":"TL;DR","text":"<p>Editing this documentation is easy, just edit the markdown files in the <code>docs</code> folder and push to the <code>main</code> branch. The documentation will be automatically built and deployed to GitHub Pages.</p>"},{"location":"contribution/editing_docs/#installation","title":"Installation","text":"<p>Install the latest version of MkDocs with <code>pip</code>:</p> <pre><code>pip install mkdocs mkdocs-material\n</code></pre>"},{"location":"contribution/editing_docs/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> <li><code>mkdocs gh-deploy</code> - Deploy to GitHub Pages </li> </ul> <p>mkdocs are automatically built and deployed to GitHub Pages using GitHub Actions. The configuration for this can be found in <code>.github/workflows/deploy_docs.yml</code>.</p>"},{"location":"contribution/editing_docs/#deploying-to-github-pages","title":"Deploying to GitHub Pages","text":"<p>To deploy the documentation to GitHub Pages, run the following command:</p> <pre><code>mkdocs gh-deploy\n</code></pre>"},{"location":"contribution/editing_docs/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"contribution/instructions_for_pre-commit/","title":"Instructions for pre-commit","text":""},{"location":"contribution/instructions_for_pre-commit/#installation","title":"Installation","text":"<p>In the root directory of the project, run the following commands: <pre><code>pip install -r src/requirements.txt -r src/requirements-dev.txt \n\npre-commit install\n</code></pre></p>"},{"location":"contribution/instructions_for_pre-commit/#usage","title":"Usage","text":"<p><code>pre-commit run --all-files</code> to run all hooks on all files.</p> <p>Just commit as usual. The pre-commit hook will run automatically.</p> <p>REMINDER: You have to re-run <code>git add</code> after the pre-commit hook runs. </p>"},{"location":"contribution/instructions_for_pre-commit/#adding-a-new-hook","title":"Adding a new hook","text":"<p>To add a new hook, add a new entry to <code>.pre-commit-config.yaml</code>.</p> <p>Then run <code>pre-commit install</code> to install the hook.</p>"},{"location":"contribution/style_guide/","title":"Style Guide","text":""},{"location":"contribution/style_guide/#linting","title":"Linting","text":"<p>We follow black and flake8 for our style guide. We use black to format our code and flake8 to check for style errors. We use pre-commit to run black and flake8 before every commit.</p> <p>Please see the pre-commit setup instructions for more information on how to set up pre-commit.</p>"},{"location":"contribution/style_guide/#docstrings","title":"Docstrings","text":"<p>Docstrings are reccomended for most functions and classes. You are not required to do them for the smallest classes, etc. but please do them for anything that is not obvious. - We use Google Style Docstrings</p> <pre><code>def start_transcription(file: File, model_type: str, user_id: Optional[str] = None):\n\"\"\"\n    Start transcription of an audio file using Whisper.\n    Use ThreadPoolExecutor to run in the background.\n    Args:\n        file (File): Audio file to be transcribed.\n        model_type (str): Model type to use for transcription (e.g. 'large', 'tiny.en')\n        user_id (str, optional): ID of the user who uploaded the audio file (default=None).\n    Returns:\n        str: JSON string representation of a TranscriptionJob object.\n    \"\"\"\n</code></pre>"},{"location":"contribution/style_guide/#testing","title":"Testing","text":"<p>Please write tests for your code. We use pytest for our testing framework. </p> <p>Tests are located in the <code>src/tests</code> directory!  You can run all tests with <code>pytest</code> from the root directory. Simple! See pytest documentation for more information.</p>"},{"location":"contribution/style_guide/#type-hints","title":"Type Hints","text":"<p>We encourage type hints for all functions and classes. Please see PEP 484 for more information on type hints.</p>"},{"location":"contribution/style_guide/#other","title":"Other","text":"<p>Please be sure to use good code practices. Some things to especially keep in mind:</p> <ul> <li>Use descriptive variable names</li> <li>DRY (Don't Repeat Yourself)</li> <li>Use comments when necessary</li> <li>Break up long functions into smaller functions</li> </ul> <p>We do not strictly adhere to the google styleguide, but we encourage you to follow it:  https://google.github.io/styleguide/pyguide.html</p>"}]}